"""
Performance monitoring and diagnostics for CRAG system.

This module provides timing decorators and diagnostic tools to identify
performance bottlenecks in the CRAG pipeline.
"""
from __future__ import annotations

import time
from functools import wraps
from typing import Callable, Dict, List, Optional

try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    torch = None


def timing_decorator(func: Callable) -> Callable:
    """
    Decorator to measure function execution time.
    
    Usage:
        @timing_decorator
        def my_function():
            pass
    """
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        end_time = time.time()
        elapsed = end_time - start_time
        print(f"â±ï¸  {func.__name__} è€—æ—¶: {elapsed:.2f}ç§’")
        return result
    return wrapper


class PerformanceMonitor:
    """Monitor and track performance metrics."""
    
    def __init__(self):
        self.metrics: Dict[str, List[float]] = {}
    
    def record(self, operation: str, duration: float):
        """Record a performance metric."""
        if operation not in self.metrics:
            self.metrics[operation] = []
        self.metrics[operation].append(duration)
    
    def get_stats(self) -> Dict[str, Dict[str, float]]:
        """Get statistics for all recorded operations."""
        stats = {}
        for operation, durations in self.metrics.items():
            if durations:
                stats[operation] = {
                    "count": len(durations),
                    "total": sum(durations),
                    "avg": sum(durations) / len(durations),
                    "min": min(durations),
                    "max": max(durations),
                }
        return stats
    
    def print_summary(self):
        """Print performance summary."""
        print("\n" + "="*60)
        print("ğŸ“Š CRAG æ€§èƒ½ç»Ÿè®¡")
        print("="*60)
        
        stats = self.get_stats()
        for operation, stat in stats.items():
            print(f"\n{operation}:")
            print(f"  è°ƒç”¨æ¬¡æ•°: {stat['count']}")
            print(f"  æ€»è€—æ—¶: {stat['total']:.2f}ç§’")
            print(f"  å¹³å‡è€—æ—¶: {stat['avg']:.3f}ç§’")
            print(f"  æœ€å¿«: {stat['min']:.3f}ç§’")
            print(f"  æœ€æ…¢: {stat['max']:.3f}ç§’")
        
        print("="*60 + "\n")


def check_gpu_status() -> Dict[str, any]:
    """
    Check GPU availability and status.
    
    Returns:
        Dictionary with GPU information.
    """
    info = {
        "cuda_available": False,
        "device_name": None,
        "gpu_memory_total": None,
        "gpu_memory_allocated": None,
    }
    
    if TORCH_AVAILABLE and torch.cuda.is_available():
        info["cuda_available"] = True
        info["device_name"] = torch.cuda.get_device_name(0)
        info["gpu_memory_total"] = torch.cuda.get_device_properties(0).total_memory / 1024**3
        info["gpu_memory_allocated"] = torch.cuda.memory_allocated(0) / 1024**3
    
    return info


def print_gpu_status():
    """Print GPU status information."""
    status = check_gpu_status()
    
    print("\n" + "="*60)
    print("ğŸ–¥ï¸  GPU çŠ¶æ€æ£€æŸ¥")
    print("="*60)
    
    if status["cuda_available"]:
        print(f"âœ… GPU å¯ç”¨: {status['device_name']}")
        print(f"   æ€»å†…å­˜: {status['gpu_memory_total']:.2f} GB")
        print(f"   å·²ä½¿ç”¨: {status['gpu_memory_allocated']:.2f} GB")
    else:
        print("âŒ GPU ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ CPUï¼ˆæ€§èƒ½è¾ƒæ…¢ï¼‰")
    
    print("="*60 + "\n")


def diagnostic_test(
    evaluator,
    num_documents: int = 12,
    batch_size: int = 4,
) -> Dict[str, float]:
    """
    Run diagnostic test to identify performance issues.
    
    Args:
        evaluator: SemanticRetrievalEvaluator instance.
        num_documents: Number of test documents.
        batch_size: Batch size for evaluation.
        
    Returns:
        Dictionary with diagnostic results.
    """
    print("\n" + "="*60)
    print("ğŸ” CRAG æ€§èƒ½è¯Šæ–­æµ‹è¯•")
    print("="*60)
    
    # Check GPU
    print_gpu_status()
    
    # Test data
    test_query = "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ "
    test_documents = [
        "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä¸»è¦ç ”ç©¶è®¡ç®—æœºå¦‚ä½•æ¨¡æ‹Ÿäººç±»å­¦ä¹ è¡Œä¸ºã€‚",
        "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œç‰¹å¾å­¦ä¹ ã€‚",
        "è‡ªç„¶è¯­è¨€å¤„ç†æ˜¯äººå·¥æ™ºèƒ½çš„å¦ä¸€ä¸ªé‡è¦åˆ†æ”¯ã€‚",
        "è®¡ç®—æœºè§†è§‰ä¸»è¦ç ”ç©¶å¦‚ä½•è®©è®¡ç®—æœºç†è§£å’Œè§£é‡Šè§†è§‰ä¿¡æ¯ã€‚",
    ] * (num_documents // 4 + 1)
    test_documents = test_documents[:num_documents]
    
    print(f"\næµ‹è¯•é…ç½®:")
    print(f"  æŸ¥è¯¢: {test_query}")
    print(f"  æ–‡æ¡£æ•°: {len(test_documents)}")
    print(f"  æ‰¹å¤„ç†å¤§å°: {batch_size}")
    
    # Test batch evaluation
    print(f"\nå¼€å§‹æ‰¹é‡è¯„ä¼°...")
    start_time = time.time()
    
    scores = evaluator.evaluate_batch(test_query, test_documents)
    
    eval_time = time.time() - start_time
    
    # Results
    results = {
        "num_documents": len(test_documents),
        "eval_time": eval_time,
        "avg_time_per_doc": eval_time / len(test_documents),
        "throughput": len(test_documents) / eval_time,
    }
    
    print(f"\nğŸ“Š è¯Šæ–­ç»“æœ:")
    print(f"  è¯„ä¼° {len(test_documents)} ä¸ªæ–‡æ¡£è€—æ—¶: {eval_time:.2f}ç§’")
    print(f"  å¹³å‡æ¯ä¸ªæ–‡æ¡£: {results['avg_time_per_doc']:.3f}ç§’")
    print(f"  ååé‡: {results['throughput']:.2f} æ–‡æ¡£/ç§’")
    
    if TORCH_AVAILABLE and torch.cuda.is_available():
        gpu_mem = torch.cuda.memory_allocated(0) / 1024**3
        print(f"  GPUå†…å­˜ä½¿ç”¨: {gpu_mem:.2f} GB")
    
    # Performance assessment
    print(f"\nğŸ“ˆ æ€§èƒ½è¯„ä¼°:")
    if results['avg_time_per_doc'] < 0.1:
        print("  âœ… ä¼˜ç§€: å¹³å‡ < 0.1ç§’/æ–‡æ¡£")
    elif results['avg_time_per_doc'] < 0.5:
        print("  âœ… è‰¯å¥½: å¹³å‡ < 0.5ç§’/æ–‡æ¡£")
    elif results['avg_time_per_doc'] < 1.0:
        print("  âš ï¸  ä¸€èˆ¬: å¹³å‡ < 1.0ç§’/æ–‡æ¡£")
    else:
        print("  ğŸ”´ è¾ƒæ…¢: å¹³å‡ > 1.0ç§’/æ–‡æ¡£")
        print("  å»ºè®®: æ£€æŸ¥GPUä½¿ç”¨ã€æ‰¹å¤„ç†å¤§å°ã€æ¨¡å‹åŠ è½½")
    
    print("="*60 + "\n")
    
    return results

